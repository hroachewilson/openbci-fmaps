_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
time_distributed_1 (TimeDist (None, 7, 40, 40, 32)     4736      
_________________________________________________________________
time_distributed_2 (TimeDist (None, 7, 38, 38, 32)     9248      
_________________________________________________________________
time_distributed_3 (TimeDist (None, 7, 19, 19, 32)     0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 7, 19, 19, 64)     18496     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 7, 19, 19, 64)     36928     
_________________________________________________________________
time_distributed_6 (TimeDist (None, 7, 9, 9, 64)       0         
_________________________________________________________________
time_distributed_7 (TimeDist (None, 7, 9, 9, 128)      73856     
_________________________________________________________________
time_distributed_8 (TimeDist (None, 7, 9, 9, 128)      147584    
_________________________________________________________________
time_distributed_9 (TimeDist (None, 7, 4, 4, 128)      0         
_________________________________________________________________
time_distributed_10 (TimeDis (None, 7, 4, 4, 256)      295168    
_________________________________________________________________
time_distributed_11 (TimeDis (None, 7, 4, 4, 256)      590080    
_________________________________________________________________
time_distributed_12 (TimeDis (None, 7, 2, 2, 256)      0         
_________________________________________________________________
time_distributed_13 (TimeDis (None, 7, 2, 2, 512)      1180160   
_________________________________________________________________
time_distributed_14 (TimeDis (None, 7, 2, 2, 512)      2359808   
_________________________________________________________________
time_distributed_15 (TimeDis (None, 7, 1, 1, 512)      0         
_________________________________________________________________
time_distributed_16 (TimeDis (None, 7, 512)            0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 7, 512)            0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 256)               787456    
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 1028      
=================================================================
Total params: 5,504,548
Trainable params: 5,504,548
Non-trainable params: 0
_________________________________________________________________
None
WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.
2018-05-22 00:56:02.243782: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Creating train generator with 15190 samples.
Epoch 1/1000
407/408 [============================>.] - ETA: 2s - loss: 1.1089 - acc: 0.4794Creating test generator with 3500 samples.
408/408 [==============================] - 1205s 3s/step - loss: 1.1080 - acc: 0.4797 - val_loss: 0.9091 - val_acc: 0.6125

Epoch 00001: val_loss improved from inf to 0.90907, saving model to data/checkpoints/lrcn-images.001-0.909.hdf5
Epoch 2/1000
408/408 [==============================] - 925s 2s/step - loss: 0.7478 - acc: 0.7031 - val_loss: 0.6970 - val_acc: 0.7195

Epoch 00002: val_loss improved from 0.90907 to 0.69703, saving model to data/checkpoints/lrcn-images.002-0.697.hdf5
Epoch 3/1000
408/408 [==============================] - 894s 2s/step - loss: 0.5864 - acc: 0.7655 - val_loss: 0.5454 - val_acc: 0.8047

Epoch 00003: val_loss improved from 0.69703 to 0.54536, saving model to data/checkpoints/lrcn-images.003-0.545.hdf5
Epoch 4/1000
408/408 [==============================] - 895s 2s/step - loss: 0.4728 - acc: 0.8120 - val_loss: 0.4726 - val_acc: 0.8453

Epoch 00004: val_loss improved from 0.54536 to 0.47255, saving model to data/checkpoints/lrcn-images.004-0.473.hdf5
Epoch 5/1000
408/408 [==============================] - 893s 2s/step - loss: 0.3869 - acc: 0.8470 - val_loss: 0.4016 - val_acc: 0.8492

Epoch 00005: val_loss improved from 0.47255 to 0.40163, saving model to data/checkpoints/lrcn-images.005-0.402.hdf5
Epoch 6/1000
408/408 [==============================] - 893s 2s/step - loss: 0.3252 - acc: 0.8749 - val_loss: 0.3404 - val_acc: 0.8859

Epoch 00006: val_loss improved from 0.40163 to 0.34042, saving model to data/checkpoints/lrcn-images.006-0.340.hdf5
Epoch 7/1000
408/408 [==============================] - 893s 2s/step - loss: 0.2758 - acc: 0.8925 - val_loss: 0.4024 - val_acc: 0.8711

Epoch 00007: val_loss did not improve from 0.34042
Epoch 8/1000
408/408 [==============================] - 894s 2s/step - loss: 0.2430 - acc: 0.9066 - val_loss: 0.3594 - val_acc: 0.8914

Epoch 00008: val_loss did not improve from 0.34042
Epoch 9/1000
408/408 [==============================] - 893s 2s/step - loss: 0.2206 - acc: 0.9093 - val_loss: 0.3044 - val_acc: 0.8906

Epoch 00009: val_loss improved from 0.34042 to 0.30438, saving model to data/checkpoints/lrcn-images.009-0.304.hdf5
Epoch 10/1000
408/408 [==============================] - 892s 2s/step - loss: 0.1986 - acc: 0.9164 - val_loss: 0.2898 - val_acc: 0.8883

Epoch 00010: val_loss improved from 0.30438 to 0.28979, saving model to data/checkpoints/lrcn-images.010-0.290.hdf5
Epoch 11/1000
408/408 [==============================] - 891s 2s/step - loss: 0.1920 - acc: 0.9189 - val_loss: 0.2978 - val_acc: 0.8961

Epoch 00011: val_loss did not improve from 0.28979
Epoch 12/1000
408/408 [==============================] - 890s 2s/step - loss: 0.1744 - acc: 0.9235 - val_loss: 0.2600 - val_acc: 0.8984

Epoch 00012: val_loss improved from 0.28979 to 0.26000, saving model to data/checkpoints/lrcn-images.012-0.260.hdf5
Epoch 13/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1646 - acc: 0.9274 - val_loss: 0.3383 - val_acc: 0.8859

Epoch 00013: val_loss did not improve from 0.26000
Epoch 14/1000
408/408 [==============================] - 890s 2s/step - loss: 0.1606 - acc: 0.9305 - val_loss: 0.2221 - val_acc: 0.9078

Epoch 00014: val_loss improved from 0.26000 to 0.22206, saving model to data/checkpoints/lrcn-images.014-0.222.hdf5
Epoch 15/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1477 - acc: 0.9357 - val_loss: 0.2687 - val_acc: 0.9031

Epoch 00015: val_loss did not improve from 0.22206
Epoch 16/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1359 - acc: 0.9393 - val_loss: 0.2701 - val_acc: 0.8938

Epoch 00016: val_loss did not improve from 0.22206
Epoch 17/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1403 - acc: 0.9368 - val_loss: 0.2494 - val_acc: 0.9070

Epoch 00017: val_loss did not improve from 0.22206
Epoch 18/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1322 - acc: 0.9395 - val_loss: 0.2542 - val_acc: 0.8992

Epoch 00018: val_loss did not improve from 0.22206
Epoch 19/1000
408/408 [==============================] - 889s 2s/step - loss: 0.1247 - acc: 0.9422 - val_loss: 0.2357 - val_acc: 0.8945

Epoch 00019: val_loss did not improve from 0.22206

